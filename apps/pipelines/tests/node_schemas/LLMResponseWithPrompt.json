{
  "description": "Uses an LLM to respond to the input.",
  "properties": {
    "tag": {
      "default": "",
      "description": "The tag that the output message should be tagged with",
      "title": "Message Tag",
      "type": "string"
    },
    "llm_provider_type": {
      "title": "Llm Provider Type",
      "type": "string",
      "ui:widget": "none"
    },
    "llm_provider_id": {
      "title": "LLM Model",
      "type": "integer",
      "ui:widget": "llm_provider_model"
    },
    "llm_provider_model_id": {
      "title": "Llm Provider Model Id",
      "type": "integer",
      "ui:widget": "none"
    },
    "llm_temperature": {
      "default": 0.7,
      "maximum": 2.0,
      "minimum": 0.0,
      "title": "Temperature",
      "type": "number",
      "ui:widget": "range"
    },
    "history_type": {
      "enum": [
        "node",
        "named",
        "global",
        "none"
      ],
      "title": "PipelineChatHistoryTypes",
      "type": "string",
      "default": "global",
      "ui:enumLabels": [
        "Node",
        "Named",
        "Global",
        "No History"
      ],
      "ui:widget": "history"
    },
    "history_name": {
      "default": null,
      "title": "History Name",
      "ui:widget": "none",
      "type": "string"
    },
    "history_mode": {
      "enum": [
        "summarize",
        "truncate_tokens",
        "max_history_length"
      ],
      "title": "PipelineChatHistoryModes",
      "type": "string",
      "default": "summarize",
      "ui:enumLabels": [
        "Summarize",
        "Truncate Tokens",
        "Max History Length"
      ],
      "ui:widget": "history_mode"
    },
    "user_max_token_limit": {
      "default": null,
      "title": "User Max Token Limit",
      "ui:widget": "none",
      "type": "integer"
    },
    "max_history_length": {
      "default": 10,
      "title": "Max History Length",
      "type": "integer",
      "ui:widget": "none"
    },
    "name": {
      "title": "Node Name",
      "type": "string",
      "ui:widget": "node_name"
    },
    "source_material_id": {
      "default": null,
      "title": "Source Material Id",
      "ui:optionsSource": "source_material",
      "ui:widget": "select",
      "type": "integer"
    },
    "prompt": {
      "default": "You are a helpful assistant. Answer the user's query as best you can",
      "title": "Prompt",
      "type": "string",
      "ui:optionsSource": "text_editor_autocomplete_vars_llm_node",
      "ui:widget": "text_editor_widget"
    },
    "collection_id": {
      "default": null,
      "title": "Media",
      "ui:optionsSource": "collection",
      "ui:widget": "select",
      "type": "integer"
    },
    "collection_index_id": {
      "default": null,
      "title": "Collection Index",
      "ui:optionsSource": "collection_index",
      "ui:widget": "select",
      "type": "integer"
    },
    "max_results": {
      "default": 20,
      "description": "The maximum number of results to retrieve from the index",
      "title": "Max Results",
      "ui:widget": "range",
      "type": "integer"
    },
    "generate_citations": {
      "default": true,
      "description": "Allow files from this collection to be referenced in LLM responses and downloaded by users",
      "title": "Generate Citations",
      "type": "boolean",
      "ui:widget": "toggle"
    },
    "tools": {
      "description": "The tools to enable for the bot",
      "items": {
        "type": "string"
      },
      "title": "Tools",
      "type": "array",
      "ui:optionsSource": "agent_tools",
      "ui:widget": "multiselect"
    },
    "custom_actions": {
      "description": "Custom actions to enable for the bot",
      "items": {
        "type": "string"
      },
      "title": "Custom Actions",
      "type": "array",
      "ui:optionsSource": "custom_actions",
      "ui:widget": "multiselect"
    },
    "built_in_tools": {
      "description": "Built in tools provided by the LLM model",
      "items": {
        "enum": [
          "web-search",
          "code-execution"
        ],
        "title": "BuiltInTools",
        "type": "string"
      },
      "title": "Built In Tools",
      "type": "array",
      "ui:conditionalField": "llm_provider_type",
      "ui:enumConditionalValues": [
        [
          "openai",
          "anthropic"
        ],
        [
          "openai"
        ]
      ],
      "ui:enumLabels": [
        "Web Search",
        "Code Execution"
      ],
      "ui:widget": "multiselect"
    },
    "tool_config": {
      "additionalProperties": {
        "anyOf": [
          {
            "properties": {},
            "title": "BuiltinToolConfig",
            "type": "object"
          },
          {
            "conditionalValue": "anthropic",
            "properties": {
              "allowed_domains": {
                "description": "Add domains without https from which you want the search results. Use space to add multiple domains",
                "items": {
                  "type": "string"
                },
                "title": "Allowed Domains",
                "type": "array",
                "ui:widget": "expandable_text"
              },
              "blocked_domains": {
                "description": "Add domains without https from which you don't want the search results. Use space to add multiple domain.",
                "items": {
                  "type": "string"
                },
                "title": "Blocked Domains",
                "type": "array",
                "ui:widget": "expandable_text"
              }
            },
            "title": "AnthropicWebSearchToolConfig",
            "tool_key": "web-search",
            "type": "object"
          }
        ]
      },
      "description": "Configuration for builtin tools",
      "title": "Tool Config",
      "type": "object",
      "ui:conditionalField": "llm_provider_type",
      "ui:widget": "built_in_tools_config"
    },
    "mcp_tools": {
      "description": "MCP tools to enable for the bot",
      "items": {
        "type": "string"
      },
      "title": "MCP Tools",
      "type": "array",
      "ui:flagRequired": "flag_mcp",
      "ui:optionsSource": "mcp_tools",
      "ui:widget": "multiselect"
    },
    "synthetic_voice_id": {
      "default": null,
      "title": "Voice Model",
      "ui:widget": "voice_widget",
      "type": "integer"
    }
  },
  "required": [
    "llm_provider_type",
    "llm_provider_id",
    "llm_provider_model_id",
    "name"
  ],
  "title": "LLMResponseWithPrompt",
  "type": "object",
  "ui:can_add": true,
  "ui:can_delete": true,
  "ui:deprecated": false,
  "ui:documentation_link": "/concepts/pipelines/nodes/#llm",
  "ui:flow_node_type": "pipelineNode",
  "ui:icon": "fa-solid fa-wand-magic-sparkles",
  "ui:label": "LLM"
}
