# Generated by Django data migration on 2025-06-03

from django.db import migrations, transaction
from django.db.models import Count


def duplicate_shared_pipelines(apps, schema_editor):
    """
    Find pipelines that are shared by multiple experiments and create individual copies
    for each experiment (except one).
    """
    Experiment = apps.get_model('experiments', 'Experiment')
    Pipeline = apps.get_model('pipelines', 'Pipeline')
    Node = apps.get_model('pipelines', 'Node')
    
    # Find pipelines shared by multiple experiments
    shared_pipelines = Pipeline.objects.annotate(
        experiment_count=Count('experiment')
    ).filter(experiment_count__gt=1)
    
    print(f"Found {shared_pipelines.count()} shared pipelines to duplicate")
    
    for shared_pipeline in shared_pipelines:
        print(f"Processing pipeline: {shared_pipeline.name} (ID: {shared_pipeline.id})")
        
        # Get all experiments using this pipeline
        experiments = list(Experiment.objects.filter(pipeline=shared_pipeline))
        print(f"  Shared by {len(experiments)} experiments")
        
        # Keep the first experiment with the original pipeline
        # Duplicate the pipeline for all other experiments
        for i, experiment in enumerate(experiments[1:], 1):
            with transaction.atomic():
                # Create a copy of the pipeline
                new_pipeline = Pipeline.objects.create(
                    team=shared_pipeline.team,
                    name=f"{shared_pipeline.name} (Copy for {experiment.name})",
                    data=shared_pipeline.data,
                    working_version=shared_pipeline.working_version,
                    version_number=shared_pipeline.version_number,
                    is_archived=shared_pipeline.is_archived,
                )
                
                # Copy all nodes from the original pipeline to the new one
                original_nodes = Node.objects.filter(pipeline=shared_pipeline)
                for node in original_nodes:
                    Node.objects.create(
                        flow_id=node.flow_id,
                        type=node.type,
                        label=node.label,
                        params=node.params,
                        working_version=node.working_version,
                        is_archived=node.is_archived,
                        pipeline=new_pipeline,
                    )
                
                # Update the experiment to use the new pipeline
                experiment.pipeline = new_pipeline
                experiment.save(update_fields=['pipeline'])
                
                print(f"  Created pipeline copy {new_pipeline.id} for experiment {experiment.name}")


def reverse_duplicate_shared_pipelines(apps, schema_editor):
    """
    This migration cannot be easily reversed as we would need to identify
    which pipelines were created by this migration and then re-associate
    experiments with the original shared pipelines.
    
    For safety, we'll raise an exception to prevent accidental reversal.
    """
    raise RuntimeError(
        "This migration cannot be reversed safely. "
        "Pipeline duplicates would need to be manually identified and removed."
    )


class Migration(migrations.Migration):

    dependencies = [
        ('experiments', '0110_alter_participantdata_data'),
        ('pipelines', '0017_pipelinechatmessages_compression_marker'),
    ]

    operations = [
        migrations.RunPython(
            duplicate_shared_pipelines,
            reverse_duplicate_shared_pipelines,
        ),
    ]